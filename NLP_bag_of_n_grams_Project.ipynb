{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFT4zbqFwRmr"
   },
   "source": [
    "### **Bag of n_grams**\n",
    "\n",
    "- Fake news refers to misinformation or disinformation in the country which is spread through word of mouth and more recently through digital communication such as What's app messages, social media posts, etc.\n",
    "\n",
    "- Fake news spreads faster than Real news and creates problems and fear among groups and in society.\n",
    "\n",
    "- We are going to address these problems using classical NLP techniques and going to classify whether a given message/ text is **Real or Fake Message**.\n",
    "\n",
    "- You will use a Bag of n-grams to pre-process the text and apply different classification algorithms.\n",
    "\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBcs8GQb0C9_"
   },
   "source": [
    "### **About Data: Fake News Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - label\n",
    "- Text is the statements or messages regarding a particular event/situation.\n",
    "\n",
    "- label feature tells whether the given Text is Fake or Real.\n",
    "\n",
    "- As there are only 2 classes, this problem comes under the **Binary Classification.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "KiYilX-lv_Vm",
    "outputId": "3a7bcc05-8e94-4d3d-c2a7-89d74f2b8202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"Fake_Real_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv(\"Fake_Real_Data.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N59dp0n1v_XU",
    "outputId": "3a438088-ff3f-4f57-9fbf-565b96693f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Fake    5000\n",
       "Real    4900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of labels \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Zr-vBY7xv_a3",
    "outputId": "1c447daa-237a-48c0-9b3f-3342f63093e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"label_num\" which gives a unique number to each of these labels \n",
    "df['label_num'] = df['label'].map({'Fake' : 0, 'Real': 1})\n",
    "\n",
    "#check the results with top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev3bWDnA3tM-"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hs94POE23Zjd"
   },
   "outputs": [],
   "source": [
    "#import train-test-split from sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                       df.Text, \n",
    "                                                       df.label_num, \n",
    "                                                       test_size=0.2, # 20% samples will go to test dataset\n",
    "                                                       random_state=2022,\n",
    "                                                       stratify=df.label_num\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I4S1PJG3ZlO",
    "outputId": "0d9865bd-48b9-4def-cfed-c740d6e02f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (7920,)\n",
      "Shape of X_test:  (1980,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2sO9uck4ILs"
   },
   "source": [
    "**Attempt 1** :\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, bigram, and trigrams.\n",
    "- use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean' distance.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLs6pmXE3Zou",
    "outputId": "1bbb4bf1-0b1e-4c5e-f751-fa4b331e772f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.49      0.65      1000\n",
      "           1       0.65      0.98      0.78       980\n",
      "\n",
      "    accuracy                           0.73      1980\n",
      "   macro avg       0.81      0.74      0.72      1980\n",
      "weighted avg       0.81      0.73      0.72      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_trigrams', CountVectorizer(ngram_range = (1, 3))),                   #using the ngram_range parameter \n",
    "                      ('KNN', (KNeighborsClassifier(n_neighbors=10, metric = 'euclidean')))           #using the KNN classifier with 10 neighbors and euclidean distance      \n",
    "                  ]\n",
    "              )\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU0g90Ra7BTW"
   },
   "source": [
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, bigram, and trigrams.\n",
    "- use **KNN** as the classifier with n_neighbors of 10 and metric as 'cosine' distance.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEsLSrIC3Zqf",
    "outputId": "b0354edc-1d3f-401b-c1ed-dd0cb7b769b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71      1000\n",
      "           1       0.69      1.00      0.81       980\n",
      "\n",
      "    accuracy                           0.77      1980\n",
      "   macro avg       0.84      0.77      0.76      1980\n",
      "weighted avg       0.84      0.77      0.76      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_trigrams', CountVectorizer(ngram_range = (1, 3))), \n",
    "                      ('KNN', KNeighborsClassifier(n_neighbors=10, metric='cosine'))\n",
    "                  ]\n",
    "              )\n",
    "    \n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl5zoCbE8jds"
   },
   "source": [
    "\n",
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bywjvZyv_ga",
    "outputId": "e2c93b51-8508-4c5a-b0ca-54e34ebe5075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1000\n",
      "           1       0.99      1.00      0.99       980\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_n_grams', CountVectorizer(ngram_range=(3,3))),\n",
    "                      ('random_forest', (RandomForestClassifier()))\n",
    "                  ]\n",
    "              )\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMeeE5zB8tZz"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use **Multinomial Naive Bayes** as the classifier with an alpha value of 0.75.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cP_zluNwBjS",
    "outputId": "108dd86a-5938-4040-9813-00b82d393ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.99      0.98      0.99       980\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_n_grams', CountVectorizer(ngram_range=(1,2))),\n",
    "                      ('MultiNB', MultinomialNB(alpha = 0.75)) \n",
    "                  ]\n",
    "              )\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoFBbMga9tPB"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R14_wUhGjqj5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 23:09:50.107131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#use this utility function to get the preprocessed text data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*do not.*',)\n",
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JIKvTbl9jql0"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_txt\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "df['preprocessed_txt'] = df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0O-uZncOjqpG",
    "outputId": "02d45596-aa7a-449d-dbba-3afd2bd8908b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>Trump Surrogate BRUTALLY Stabs Pathetic vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>U.S. conservative leader optimistic common gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>trump propose U.S. tax overhaul stir concern d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>Court Forces Ohio allow million illegally pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>Democrats Trump agree work immigration bill wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num   \n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0  \\\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1   \n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1   \n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0   \n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1   \n",
       "\n",
       "                                    preprocessed_txt  \n",
       "0    Trump Surrogate BRUTALLY Stabs Pathetic vide...  \n",
       "1  U.S. conservative leader optimistic common gro...  \n",
       "2  trump propose U.S. tax overhaul stir concern d...  \n",
       "3    Court Forces Ohio allow million illegally pu...  \n",
       "4  Democrats Trump agree work immigration bill wa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMVuYaYM-giF"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "D25BcI45jqrE"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Make sure to use only the \"preprocessed_txt\" column for splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                        df.preprocessed_txt, \n",
    "                                                        df.label_num, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42, \n",
    "                                                        stratify=df.label_num\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOh36PXR-nR_"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbfpQ5-kDgMt"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGQusE2rjquN",
    "outputId": "d1b83f99-0983-4feb-e24e-e3f9f2e09632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1000\n",
      "           1       0.99      0.93      0.96       980\n",
      "\n",
      "    accuracy                           0.96      1980\n",
      "   macro avg       0.96      0.96      0.96      1980\n",
      "weighted avg       0.96      0.96      0.96      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_n_grams', CountVectorizer(ngram_range = (3, 3))),\n",
    "                      ('random_forest', (RandomForestClassifier()))\n",
    "                  ]\n",
    "              )\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB78pcAPEFQZ"
   },
   "source": [
    "**Attempt2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, Bigram, and trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpwvD1mvjqvx",
    "outputId": "bbee2e0b-98da-4ae0-a480-259e0de8fa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1000\n",
      "           1       1.00      0.99      0.99       980\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline(\n",
    "                  [\n",
    "                      ('vectorizer_n_grams', CountVectorizer(ngram_range = (1, 3))),\n",
    "                      ('random_forest', (RandomForestClassifier()))\n",
    "                  ]\n",
    "              )\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM [[997   3]\n",
      " [  7 973]]\n"
     ]
    }
   ],
   "source": [
    "#finally print the confusion matrix for the best model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('CM {}'.format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "SLT0vKGRHAMF",
    "outputId": "540746d1-2dec-4585-918b-c4afba111e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSfKnzG4EYSn"
   },
   "source": [
    "## **Final Observations**\n",
    "- As machine learning algorithms do not work on text data directly, we need to convert them into numeric vectors and feed that into models while training.\n",
    "\n",
    "\n",
    "- In this process, we convert text into a very high dimensional numeric vector using the technique of Bag of words and we use sklearn CountVectorizer for this.\n",
    "\n",
    "\n",
    "\n",
    "#### **Without Pre-Processing Data**\n",
    "\n",
    "\n",
    "- From the above in most of the cases, we can see that when we have the count vectorizer above trigrams or at trigrams, the performance keeps degrading. The major possible reason for this as the ngram_range keeps increasing, the number of dimensions/features (possible combination of words) also increases enormously and models have the risk of overfitting and resulting in terrible performance.\n",
    "\n",
    "\n",
    "- For this reason, models like KNN failed terribly when performed with trigrams and using the euclidean distance. K-Nearest Neighbours(KNN) doesn't work well with high-dimensional data because, with a large number of dimensions, it becomes difficult for the algorithm to calculate the distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of the model. It performed well for class 1 and had terrible results for Class 0.\n",
    "\n",
    "\n",
    "- Both recall and F1 scores increase better when trained with the same KNN model but with cosine distance as cosine distance does not get influenced by the number of dimensions as it uses the angle better the two text vectors to calculate the similarity.\n",
    "\n",
    "\n",
    "- With respect to Naive and RandomForest models, both performed really well, and random forest with trigrams has a better edge on the recall metric.\n",
    "\n",
    "\n",
    "- As Random Forest uses Bootstrapping(row and column Sampling) with many decision trees and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifying the categories.\n",
    "\n",
    "\n",
    "- The easy calculation of probabilities for the words in the corpus(Bag of words) and storing them in a contingency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
    "\n",
    "#### With Pre-Processing Data\n",
    "- Have trained the best model RandomForest on the pre-processed data, but RandomForest with trigrams fails to produce the same results here.\n",
    "\n",
    "\n",
    "- But the same randomForest with Unigram to Trigram features helps to produce very amazing results and is tops in the entire list with very good F1 scores and Recall scores.\n",
    "\n",
    "\n",
    "<p><b>Machine Learning is like a trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which gives good results and satisfies the requirements like latency, interpretability, etc.</b></p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bag_of_n_grams_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
